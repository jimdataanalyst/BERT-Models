{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1603801131368
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer,BertForMaskedLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "from tqdm import tqdm\n",
    "#from early_stopping import EarlyStopping\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1603801131866
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1603801132325
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        data = data.reset_index()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = data.text\n",
    "        self.targets = data.targets\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1603801132655
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class DistillBERTForRegression(torch.nn.Module):\n",
    "    def __init__(self, layer_size=768, dropout=0.3):\n",
    "        super(DistillBERTForRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"../jimharrington.johnselvynnallathambi/amd_bert-base-uncased\")\n",
    "        #self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.hidden_layer = torch.nn.Linear(768, layer_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.classifier = torch.nn.Linear(layer_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # BERT \"pooling\": https://github.com/huggingface/transformers/issues/1535\n",
    "        bert_output = output_1[0][:, 0]\n",
    "        x = self.hidden_layer(bert_output)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        # With dropout\n",
    "        x = self.dropout(x)\n",
    "        # Final layer\n",
    "        x = self.classifier(x)\n",
    "        return torch.nn.ReLU()(x)\n",
    "\n",
    "    def eval_with_dict(self, data):\n",
    "        return self(\n",
    "            data['input_ids'].to(device, dtype=torch.long),\n",
    "            data['attention_mask'].to(device, dtype=torch.long),\n",
    "            data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        ).squeeze(1)\n",
    "\n",
    "    def eval_with_loader(self, loader):\n",
    "        self.eval()\n",
    "        fin_targets = []\n",
    "        fin_outputs = []\n",
    "        with torch.no_grad():\n",
    "            for _, data in enumerate(loader, 0):\n",
    "                predictions = self.eval_with_dict(data)\n",
    "                fin_targets.extend(data['targets'].tolist())\n",
    "                fin_outputs.extend(predictions.to(\"cpu\").detach().numpy().tolist())\n",
    "        return fin_outputs, fin_targets\n",
    "\n",
    "\n",
    "def compute_abs_error(predictions, targets, scaler):\n",
    "    return torch.abs(\n",
    "        untransform(predictions, scaler) - untransform(targets, scaler)\n",
    "    ).sum().data\n",
    "\n",
    "\n",
    "def untransform(y, scaler):\n",
    "    return ( y * (scaler.data_max_[0] - scaler.data_min_[0]) + scaler.data_min_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1603801133439
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, dataset, tokenizer, learning_rate, patience, train_batch_size, test_batch_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.patience = patience\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.max_length = tokenizer.model_max_length\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "\n",
    "        self.prepare_data(dataset)\n",
    "\n",
    "    def prepare_data(self, dataset):\n",
    "        train_dataset, test_dataset = train_test_split(dataset, test_size=0.25, random_state=0)\n",
    "        test_dataset, valid_dataset = train_test_split(test_dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "        # Normalization\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(train_dataset[['targets']])\n",
    "        train_dataset['targets'] = self.scaler.transform(train_dataset[['targets']])\n",
    "        test_dataset['targets'] = self.scaler.transform(test_dataset[['targets']])\n",
    "        valid_dataset['targets'] = self.scaler.transform(valid_dataset[['targets']])\n",
    "\n",
    "        # Create datasets\n",
    "        training_set = CustomDataset(train_dataset, self.tokenizer, self.max_length)\n",
    "        test_set = CustomDataset(test_dataset, self.tokenizer, self.max_length)\n",
    "        valid_set = CustomDataset(valid_dataset, self.tokenizer, self.max_length)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_params = {\n",
    "            'batch_size': self.train_batch_size,\n",
    "            'shuffle': True\n",
    "        }\n",
    "        test_params = {\n",
    "            'batch_size': self.test_batch_size,\n",
    "            'shuffle': False\n",
    "        }\n",
    "        self.training_loader = DataLoader(training_set, **train_params)\n",
    "        self.test_loader = DataLoader(test_set, **test_params)\n",
    "        self.valid_loader = DataLoader(valid_set, **test_params)\n",
    "\n",
    "    def train(self, model, nb_epochs):\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        for epoch in range(nb_epochs):\n",
    "            # Training part\n",
    "            model.train()\n",
    "            training_abs_err, train_loss = 0, 0\n",
    "            for _, data in tqdm(\n",
    "                        enumerate(self.training_loader),\n",
    "                        total=len(self.training_loader),\n",
    "                        desc=f\"Epoch {epoch + 1}\",\n",
    "                        miniters=10\n",
    "                    ):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "                outputs = model.eval_with_dict(data)\n",
    "\n",
    "                # Compute loss and other metrics\n",
    "                loss = self.loss(outputs, targets)\n",
    "                train_loss += loss.item()\n",
    "                training_abs_err += compute_abs_error(outputs, targets, self.scaler)\n",
    "\n",
    "                # compute gradients and perform one optimization step\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # End of epoch: run validation & print train and validation scores\n",
    "            # Validation part\n",
    "            model.eval()\n",
    "            valid_abs_error, valid_loss = 0, 0\n",
    "            for data in self.valid_loader:\n",
    "                targets = data['targets'].to(device, dtype=torch.float)\n",
    "                outputs = model.eval_with_dict(data)\n",
    "                loss = self.loss(outputs, targets)\n",
    "                valid_loss += loss.item()\n",
    "                valid_abs_error += compute_abs_error(outputs, targets, self.scaler)\n",
    "\n",
    "            # Scores\n",
    "            valid_mae = valid_abs_error / len(self.valid_loader.dataset)\n",
    "            valid_loss = valid_loss / len(self.valid_loader.dataset)\n",
    "\n",
    "            train_mae = training_abs_err / len(self.training_loader.dataset)\n",
    "            train_loss = train_loss / len(self.training_loader.dataset)\n",
    "            print((\n",
    "                f\"Epoch {epoch + 1} / {nb_epochs}, Loss: {train_loss:.3f}, MAE: {train_mae:.1f} \"\n",
    "                f\"- Validation Loss: {valid_loss:.3f}, Validation MAE: {valid_mae:.1f}\"))\n",
    "\n",
    "    \n",
    "\n",
    "        # Return best (checkpointed) model\n",
    "        #model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "        return model\n",
    "        \n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred)[y_true > 0] / (y_true + 1e-7)[y_true > 0])) * 100\n",
    "\n",
    "\n",
    "def max_absolute_error(y_true, y_pred):\n",
    "    return np.max(np.abs((y_true - y_pred)))\n",
    "\n",
    "\n",
    "def compute_metrics(y_test, y_pred):\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    # print(f\"r2: {r2_score(y_test, y_pred)}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MedAE: {median_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MaxAE: {max_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MAPE: {mean_absolute_percentage_error(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1603801140164
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTForRegression(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35521, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (hidden_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTForRegression(\n",
    "        layer_size=768,\n",
    "        dropout=0.3)\n",
    " \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1603801144488
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"../jimharrington.johnselvynnallathambi/data_sizing_bin1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1603801144866
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df['Sizing_bins']=df['Sizing_bins'].replace(['Very Small','Small','Medium','Large'], [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1603801145136
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11113 entries, 0 to 11112\n",
      "Data columns (total 51 columns):\n",
      "Unnamed: 0                           11113 non-null int64\n",
      "Unnamed: 0.1                         11113 non-null int64\n",
      "TaskID                               11113 non-null int64\n",
      "Title                                11113 non-null object\n",
      "DomainID                             11113 non-null int64\n",
      "Domain                               11113 non-null object\n",
      "AreaID                               8669 non-null float64\n",
      "Area                                 8669 non-null object\n",
      "BudgetLineID                         9385 non-null float64\n",
      "BudgetLine                           9385 non-null object\n",
      "ProjectID                            11113 non-null int64\n",
      "ProjectName                          11113 non-null object\n",
      "ProjectDescription                   11113 non-null object\n",
      "RegionID                             9672 non-null float64\n",
      "Region                               9672 non-null object\n",
      "CurrentProcess                       11113 non-null object\n",
      "PCPNumber                            11113 non-null int64\n",
      "CR                                   3751 non-null float64\n",
      "PCPType                              11113 non-null object\n",
      "FundingSolution                      8716 non-null object\n",
      "TaskStatus                           11113 non-null object\n",
      "DescopeReason                        4487 non-null object\n",
      "Sizing                               7524 non-null float64\n",
      "OOM                                  1548 non-null float64\n",
      "OOMStr                               555 non-null object\n",
      "AssessmentCategory                   11113 non-null object\n",
      "CategoryKeyword                      2975 non-null object\n",
      "LateUATJustification                 709 non-null object\n",
      "OOMForumReview                       8713 non-null object\n",
      "OOMForumApproved                     38 non-null float64\n",
      "ExpiryFlag                           469 non-null float64\n",
      "DateOpen                             11113 non-null object\n",
      "OpenYear                             11113 non-null int64\n",
      "AssessmentMode                       8431 non-null object\n",
      "UATDuration                          26 non-null float64\n",
      "RequirementDescription               11042 non-null object\n",
      "SolutionSummary                      7119 non-null object\n",
      "SolutionDescription                  7323 non-null object\n",
      "SolutionAssumption                   4158 non-null object\n",
      "OOMForumComments                     19 non-null object\n",
      "OOMComments                          264 non-null object\n",
      "AssessmentInfoComments               8 non-null object\n",
      "PCPComments                          1133 non-null object\n",
      "ProductName                          8020 non-null object\n",
      "PCPCategory                          8821 non-null object\n",
      "Itemization                          8249 non-null object\n",
      "RecommendedPricing                   10849 non-null object\n",
      "UpdatedDate                          11113 non-null object\n",
      "totalwords_RequirementDescription    11037 non-null float64\n",
      "Sizing_cpy                           7524 non-null float64\n",
      "Sizing_bins                          7348 non-null float64\n",
      "dtypes: float64(12), int64(7), object(32)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1603801145402
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AHP CRS                        799\n",
       "e-commerce suite               548\n",
       "Altea DCS - CM                 453\n",
       "Webservices                    413\n",
       "Altea DCS                      372\n",
       "                              ... \n",
       "Name Change Controller           1\n",
       "ATC Auto-Revalidation            1\n",
       "LSS trusted (after 3 years)      1\n",
       "IRU                              1\n",
       "AGY                              1\n",
       "Name: ProductName, Length: 161, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ProductName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1603801145731
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=df[['Title','Domain','Area','BudgetLine','ProjectDescription','Region','RequirementDescription','RecommendedPricing','Sizing_bins','totalwords_RequirementDescription', 'Sizing_cpy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1603801146162
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11037.000000\n",
       "mean        95.905047\n",
       "std        103.927854\n",
       "min          1.000000\n",
       "25%         35.000000\n",
       "50%         71.000000\n",
       "75%        119.000000\n",
       "max       1763.000000\n",
       "Name: totalwords_RequirementDescription, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['totalwords_RequirementDescription'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1603801146451
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=df[(df['totalwords_RequirementDescription']>=30)&(df['totalwords_RequirementDescription']<=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1603801146778
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop(['totalwords_RequirementDescription'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1603801147080
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#df=df[df['ProductName']=='e-commerce suite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1603801147342
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1603801147636
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1603801147955
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['Text']=0\n",
    "for i in range(len(df)):\n",
    " df['Text'][i] = str(df['Title'][i]) +\" \"+str(df['Domain'][i]) +\" \"+ str(df['Area'][i])+\" \"+str(df['BudgetLine'][i])+' '+str(df['ProjectDescription'][i])+\" \"+str(df['Region'][i])+' '+ str(df['RequirementDescription'][i])+' '+str(df['RecommendedPricing'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1603801148258
    }
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['RequirementDescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1603801148554
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       SWA want a mechanism to be able to upload an O...\n",
       "1       NT flights departing from stations in Cabo Ver...\n",
       "2       This Task has been automatically created by im...\n",
       "3       In Scope: To insert a notice line, in the all ...\n",
       "4       This Task has been automatically created by im...\n",
       "                              ...                        \n",
       "2502    This Task has been automatically created by im...\n",
       "2503    This Task has been automatically created by im...\n",
       "2504    This Task has been automatically created by im...\n",
       "2505    \\n\\nAdding COVID 20 to enable FTC transfer on ...\n",
       "2506    \\n\\n!Please use the CP Word document template ...\n",
       "Name: Text, Length: 2507, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1603801148865
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df=df[['Text','Sizing_bins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1603801149172
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.columns = ['text','targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1603801149420
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "REMOVE_NUMBERS =re.compile(\"[\\d+]\")\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = REMOVE_NUMBERS.sub('',text) # replace REMOVE_NUMBERS by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "#     text = ' '.join(word for word in text.split() if word not in STOPWORDS)# delete stopwors from text\n",
    "    #text = ' '.join(word for word in text.split() if word not in common_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1603801149689
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1603801150010
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swa want a mechanism to be able to upload an o...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nt flights departing from stations in cabo ver...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this task has been automatically created by im...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in scope to insert a notice line  in the all i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this task has been automatically created by im...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  targets\n",
       "0  swa want a mechanism to be able to upload an o...      2.0\n",
       "1  nt flights departing from stations in cabo ver...      0.0\n",
       "2  this task has been automatically created by im...      1.0\n",
       "3  in scope to insert a notice line  in the all i...      0.0\n",
       "4  this task has been automatically created by im...      1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1603732630392
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer = Trainer(\n",
    "    dataset=df,\n",
    "    tokenizer=BertTokenizer.from_pretrained('bert-base-uncased'),\n",
    "    learning_rate=4e-6,\n",
    "    patience=5,\n",
    "    train_batch_size=7,\n",
    "    test_batch_size=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1603736375945
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 2:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10, Loss: 0.015, MAE: 0.8 - Validation Loss: 0.019, Validation MAE: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 3:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10, Loss: 0.013, MAE: 0.7 - Validation Loss: 0.018, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 4:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10, Loss: 0.012, MAE: 0.7 - Validation Loss: 0.020, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 5:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10, Loss: 0.011, MAE: 0.6 - Validation Loss: 0.021, Validation MAE: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 6:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10, Loss: 0.010, MAE: 0.6 - Validation Loss: 0.020, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 7:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10, Loss: 0.009, MAE: 0.5 - Validation Loss: 0.021, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 8:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10, Loss: 0.008, MAE: 0.5 - Validation Loss: 0.022, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n",
      "Epoch 9:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10, Loss: 0.006, MAE: 0.5 - Validation Loss: 0.021, Validation MAE: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 269/269 [05:48<00:00,  1.30s/it]\n",
      "Epoch 10:   0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10, Loss: 0.005, MAE: 0.4 - Validation Loss: 0.024, Validation MAE: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 269/269 [05:49<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 10, Loss: 0.004, MAE: 0.4 - Validation Loss: 0.028, Validation MAE: 0.8\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1603736412364
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9877925858768093\n",
      "MAE: 0.7430932072331449\n",
      "MedAE: 0.6109760105609894\n",
      "MaxAE: 2.86793277785182\n",
      "MAPE: 156.94999566336222\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "preds, targets = model.eval_with_loader(trainer.test_loader)\n",
    "preds_untr= trainer.scaler.inverse_transform([preds])[0,:]\n",
    "targets_untr = trainer.scaler.inverse_transform([targets])[0,:] \n",
    "compute_metrics(preds_untr, targets_untr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1603736412598
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.03387368, 2.08082378, 1.63990116, 1.27147427, 1.95019251,\n",
       "       2.07503772, 0.        , 1.22221372, 0.2605661 , 1.62222272,\n",
       "       0.99858561, 0.3357857 , 1.14696908, 0.64680228, 0.08485775,\n",
       "       0.        , 0.        , 0.        , 0.40710729, 1.53721297,\n",
       "       0.67867953, 0.29821461, 3.03083289, 1.00269198, 2.33496451,\n",
       "       1.19269788, 1.2369487 , 0.30763462, 0.65266237, 0.        ,\n",
       "       1.94005734, 0.64871764, 2.35396206, 0.        , 0.7868304 ,\n",
       "       0.3357857 , 0.        , 0.40875506, 0.14590912, 0.08971315,\n",
       "       0.        , 1.60781515, 1.89224714, 0.        , 0.84299281,\n",
       "       2.47798777, 0.49098627, 0.04837895, 0.3357857 , 2.21186364,\n",
       "       0.35913527, 0.        , 0.71096018, 0.        , 1.05538791,\n",
       "       0.3357857 , 0.        , 0.50036712, 0.64292751, 1.19469327,\n",
       "       1.00702974, 0.51073435, 1.86236197, 1.07454389, 1.07039148,\n",
       "       1.19836593, 1.11355966, 0.64424756, 0.51013514, 0.80456069,\n",
       "       0.        , 0.38332218, 0.48245725, 0.60322326, 1.36392814,\n",
       "       0.84667003, 0.44454794, 1.47235867, 0.        , 0.        ,\n",
       "       2.550286  , 2.1049946 , 1.27707034, 0.3357857 , 0.3357857 ,\n",
       "       1.32179001, 1.07872573, 0.81538591, 1.16220546, 0.39817952,\n",
       "       1.93476945, 0.        , 0.99486262, 0.70874476, 1.95655757,\n",
       "       2.56931752, 2.80603355, 1.06475911, 2.05812639, 2.26805359,\n",
       "       1.51944834, 0.        , 0.82250217, 1.74277192, 1.52225626,\n",
       "       1.13202006, 1.83905643, 0.56895536, 0.37847306, 0.        ,\n",
       "       1.22271922, 1.76492089, 0.        , 1.03872871, 0.71971357,\n",
       "       0.17032755, 0.3357857 , 0.        , 0.65334356, 1.19721597,\n",
       "       2.11720794, 1.55244541, 1.25536054, 1.5896641 , 1.1731672 ,\n",
       "       0.44018774, 2.41137886, 1.85436326, 0.55456598, 0.7544193 ,\n",
       "       1.25890991, 0.        , 2.36717677, 1.23046803, 0.16045552,\n",
       "       0.34674288, 1.77305371, 0.62865275, 0.        , 0.21266055,\n",
       "       0.65150151, 0.        , 1.06605282, 0.        , 0.97351831,\n",
       "       0.3357857 , 0.77445289, 2.12669277, 2.50512278, 1.26575053,\n",
       "       1.085316  , 1.72751874, 1.84715688, 1.86114299, 2.3464399 ,\n",
       "       0.        , 1.10465571, 1.73711568, 2.13232899, 0.47774966,\n",
       "       1.29912829, 1.61599392, 1.64980155, 0.01878524, 1.11418658,\n",
       "       1.41577891, 0.28668027, 0.        , 1.63944948, 0.89034292,\n",
       "       0.44948789, 1.21637142, 2.09711373, 2.14558572, 0.05813556,\n",
       "       0.        , 0.15305189, 0.75244197, 0.01645378, 0.02981152,\n",
       "       3.2638582 , 0.        , 1.09709117, 0.        , 1.65144181,\n",
       "       1.35544422, 2.70175785, 0.9787977 , 2.19405931, 0.89125997,\n",
       "       0.75344199, 0.6849373 , 0.3357857 , 2.10319054, 2.27374238,\n",
       "       0.3357857 , 1.31071508, 0.        , 2.26281559, 1.41364977,\n",
       "       0.        , 1.54724568, 0.39492282, 0.87722164, 0.        ,\n",
       "       2.40459323, 0.        , 1.77990532, 2.5063076 , 0.73775581,\n",
       "       1.59826005, 0.        , 2.32099271, 1.78257465, 0.67226395,\n",
       "       1.19912767, 0.        , 0.        , 2.1399622 , 1.32399175,\n",
       "       1.17746669, 0.73377639, 0.44965017, 0.40762438, 2.00751257,\n",
       "       1.32441482, 1.25495312, 0.78897473, 0.6120446 , 0.82929039,\n",
       "       1.99358618, 1.43023726, 1.87157643, 0.        , 0.        ,\n",
       "       0.44484356, 2.38228208, 1.73469079, 2.09679937, 0.09091724,\n",
       "       1.41561404, 0.        , 3.04960084, 2.44620752, 1.77934492,\n",
       "       0.50256081, 0.        , 0.        , 1.73919296, 1.94733292,\n",
       "       2.19462276, 0.        , 1.36883748, 0.13206722, 0.80549455,\n",
       "       0.        , 0.        , 1.34120277, 1.97045428, 0.8702116 ,\n",
       "       1.23149148, 0.65283707, 2.53571302, 0.3357857 , 1.33749694,\n",
       "       2.60980099, 1.34444466, 1.88653868, 0.95422572, 1.41787496,\n",
       "       0.        , 0.38902402, 1.29766479, 0.78863946, 3.10367954,\n",
       "       1.31717697, 1.8526116 , 0.38105965, 3.01320899, 0.46133356,\n",
       "       1.11641157, 1.01350245, 2.90068209, 1.01090455, 0.37495865,\n",
       "       1.25477439, 1.5273174 , 1.00838685, 1.8214556 , 0.3357857 ,\n",
       "       0.18901643, 2.34833211, 3.55167568, 0.3357857 , 1.53701735,\n",
       "       1.15278742, 1.44224229, 0.02534068, 1.74244326, 0.3357857 ,\n",
       "       0.        , 1.32421187, 0.        , 1.72880459, 0.        ,\n",
       "       0.        , 1.61974669, 0.36121733, 0.96511862, 0.08119062,\n",
       "       0.39289726, 0.13293612, 1.38410041, 0.        , 1.89410287,\n",
       "       2.7154938 , 0.78492719, 2.21080166, 0.05304452, 0.70333421,\n",
       "       0.86027902, 0.16858597, 1.90070879, 0.75895527, 0.3357857 ,\n",
       "       1.90893799, 2.39569026, 1.58018821, 1.24588171, 0.        ,\n",
       "       0.67309883, 0.        , 0.3357857 , 1.68915743, 0.3357857 ,\n",
       "       2.29487532, 0.86313495, 1.69856304, 1.50187147, 0.37149167,\n",
       "       0.        , 1.82598585, 0.78815997, 0.        , 0.        ,\n",
       "       0.3357857 , 2.25602245, 2.3636502 , 0.49078904, 1.68858021,\n",
       "       0.73045608, 0.03264853, 2.37815559, 0.71676385, 0.        ,\n",
       "       0.        , 0.3357857 , 1.84300125, 0.92412364, 2.11388236,\n",
       "       1.49013028, 1.05642566, 0.        , 0.3357857 , 0.400085  ,\n",
       "       1.36711219, 0.06864819, 0.83695355, 1.36140338, 0.        ,\n",
       "       0.        , 0.98771265, 0.58107202, 1.42306378, 1.52887684,\n",
       "       0.78853977, 0.04762606, 1.55442935, 0.08395668, 0.2859394 ,\n",
       "       1.25551441, 0.62262967, 1.10319471, 1.13233897, 0.65830073,\n",
       "       1.98102307, 1.64417893, 0.3357857 , 0.54677872, 1.29397058,\n",
       "       1.20743698, 2.00993854, 1.62201834, 0.81167945, 0.3357857 ,\n",
       "       0.        , 0.65186271, 0.29916376, 1.15795889, 1.81388694,\n",
       "       0.        , 2.29330516, 0.        , 1.58488315, 0.19640753,\n",
       "       1.88363475, 1.06629771, 0.        , 0.80312517, 1.90034258,\n",
       "       1.31989941, 2.33302689, 1.86804932, 1.36984375, 0.        ,\n",
       "       1.52994329, 0.31408212, 1.10194749, 0.65854204, 1.1065414 ,\n",
       "       0.3357857 , 2.43855375, 0.        , 1.23074475, 2.17978513,\n",
       "       0.3357857 , 1.08983436, 0.        , 0.60453741, 2.7232275 ,\n",
       "       1.85011554, 0.        , 0.        , 0.73172584, 0.        ,\n",
       "       2.28480774, 1.80454373, 0.        , 0.46302058, 0.46954022,\n",
       "       0.        , 0.8697153 , 2.04808259, 1.38109463, 1.2222881 ,\n",
       "       0.33485949, 1.12187621, 1.16639087, 0.        , 0.95726913,\n",
       "       0.5546886 , 1.0372434 , 0.31084277, 2.36768746, 0.96807969,\n",
       "       0.11319895, 0.91509748, 0.        , 0.        , 0.10895476,\n",
       "       0.        , 1.10755509, 1.10350826, 3.11341918, 1.18071985,\n",
       "       0.09498562, 0.        , 0.64756885, 0.        , 1.56478912,\n",
       "       0.88834003, 0.        , 1.47836557, 0.40201257, 0.88497663,\n",
       "       1.29264995, 0.73324496, 2.59258139, 0.97033489, 0.54684511,\n",
       "       0.72825417, 0.50332502, 0.3357857 , 1.48995683, 0.56853671,\n",
       "       2.09871268, 1.41397557, 0.3357857 , 2.15461689, 2.21354985,\n",
       "       0.        , 1.67162204, 0.        , 0.7622298 , 1.43492237,\n",
       "       1.86880589, 0.29631409, 0.48879862, 1.37579906, 1.41444156,\n",
       "       1.23364529])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_untr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1603736412736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pred_int= np.round(preds_untr)\n",
    "target_int = np.round(targets_untr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1603736412962
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efbdcc5c630>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#create scatterplot\n",
    "plt.scatter(targets_untr,preds_untr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1603736413267
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,  71,  35,   1,   0],\n",
       "       [ 31,  72,  36,   5,   0],\n",
       "       [ 20,  31,  34,   7,   0],\n",
       "       [  6,  12,  16,   5,   1],\n",
       "       [  0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_int, pred_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "gather": {
     "logged": 1603736413551
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.52      0.59       225\n",
      "         1.0       0.39      0.50      0.44       144\n",
      "         2.0       0.28      0.37      0.32        92\n",
      "         3.0       0.28      0.12      0.17        40\n",
      "         4.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46       501\n",
      "   macro avg       0.32      0.30      0.30       501\n",
      "weighted avg       0.49      0.46      0.46       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [0,1,2,3]\n",
    "print(classification_report(target_int, pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1603736413883
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "gather": {
     "logged": 1603736414016
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "tar=df['targets'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "gather": {
     "logged": 1603736414203
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efbdc1b34a8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tar.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "gather": {
     "logged": 1603736414353
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# df.loc[df[\"Sizing_bins\"] == 6, \"Sizing_cpy\"].plot(kind='hist')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
